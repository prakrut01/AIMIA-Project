{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80fae830",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet50\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb2812ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import gc\n",
    "\n",
    "# Clear PyTorch's CUDA cache\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Force Python garbage collection\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb05330d",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import timm\n",
    "except ImportError:\n",
    "    print(\"Installing timm library...\")\n",
    "    import subprocess\n",
    "    subprocess.check_call([\"pip\", \"install\", \"timm\"])\n",
    "    import timm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926230ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Setting up EFFICIENTNET model with modern enhancements...\n",
      "Using device: cuda\n",
      "Model: tf_efficientnet_b3\n",
      "Available GPU VRAM: 23.6 GB\n",
      "Using batch size 12 for EfficientNet\n",
      "Test images: 25596\n",
      "Train+Val images: 86524\n",
      "Train images: 69219\n",
      "Validation images: 17305\n",
      "Dataset initialized with 69219 images\n",
      "Dataset initialized with 17305 images\n",
      "Dataset initialized with 25596 images\n",
      "Train dataset size: 69219\n",
      "Validation dataset size: 17305\n",
      "Test dataset size: 25596\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 880\u001b[0m\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# Replace your main() call with:\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    878\u001b[0m     \u001b[38;5;66;03m# You can easily switch between models:\u001b[39;00m\n\u001b[1;32m    879\u001b[0m     \u001b[38;5;66;03m# main()  # For original ResNet baseline\u001b[39;00m\n\u001b[0;32m--> 880\u001b[0m     \u001b[43mmain_efficientnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# For EfficientNet improvement\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[9], line 729\u001b[0m, in \u001b[0;36mmain_efficientnet\u001b[0;34m()\u001b[0m\n\u001b[1;32m    727\u001b[0m class_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m Config\u001b[38;5;241m.\u001b[39muse_class_weights:\n\u001b[0;32m--> 729\u001b[0m     class_weights \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_class_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    731\u001b[0m \u001b[38;5;66;03m# Create data loaders\u001b[39;00m\n\u001b[1;32m    732\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m DataLoader(\n\u001b[1;32m    733\u001b[0m     train_dataset, \n\u001b[1;32m    734\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mConfig\u001b[38;5;241m.\u001b[39mbatch_size, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    737\u001b[0m     pin_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    738\u001b[0m )\n",
      "Cell \u001b[0;32mIn[9], line 625\u001b[0m, in \u001b[0;36mcalculate_class_weights\u001b[0;34m(dataset)\u001b[0m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Calculate class weights for handling imbalance\"\"\"\u001b[39;00m\n\u001b[1;32m    623\u001b[0m class_counts \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(Config\u001b[38;5;241m.\u001b[39mnum_classes)\n\u001b[0;32m--> 625\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, labels \u001b[38;5;129;01min\u001b[39;00m dataset:\n\u001b[1;32m    626\u001b[0m     class_counts \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m    628\u001b[0m \u001b[38;5;66;03m# Avoid division by zero\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[9], line 97\u001b[0m, in \u001b[0;36mChestXrayDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;66;03m# Load image\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 97\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRGB\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWarning: Could not load image \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimg_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/med_env_fixed/lib/python3.10/site-packages/PIL/Image.py:937\u001b[0m, in \u001b[0;36mImage.convert\u001b[0;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[1;32m    889\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mconvert\u001b[39m(\n\u001b[1;32m    890\u001b[0m     \u001b[38;5;28mself\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, matrix\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dither\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, palette\u001b[38;5;241m=\u001b[39mPalette\u001b[38;5;241m.\u001b[39mWEB, colors\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m\n\u001b[1;32m    891\u001b[0m ):\n\u001b[1;32m    892\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    893\u001b[0m \u001b[38;5;124;03m    Returns a converted copy of this image. For the \"P\" mode, this\u001b[39;00m\n\u001b[1;32m    894\u001b[0m \u001b[38;5;124;03m    method translates pixels through the palette.  If mode is\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    934\u001b[0m \u001b[38;5;124;03m    :returns: An :py:class:`~PIL.Image.Image` object.\u001b[39;00m\n\u001b[1;32m    935\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 937\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    939\u001b[0m     has_transparency \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransparency\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    940\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mP\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    941\u001b[0m         \u001b[38;5;66;03m# determine default mode\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/med_env_fixed/lib/python3.10/site-packages/PIL/ImageFile.py:269\u001b[0m, in \u001b[0;36mImageFile.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(msg)\n\u001b[1;32m    268\u001b[0m b \u001b[38;5;241m=\u001b[39m b \u001b[38;5;241m+\u001b[39m s\n\u001b[0;32m--> 269\u001b[0m n, err_code \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet50\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm  # Add this import\n",
    "\n",
    "# Install required packages\n",
    "try:\n",
    "    import timm\n",
    "    from tqdm import tqdm\n",
    "except ImportError:\n",
    "    print(\"Installing required libraries...\")\n",
    "    import subprocess\n",
    "    subprocess.check_call([\"pip\", \"install\", \"timm\", \"tqdm\"])\n",
    "    import timm\n",
    "    from tqdm import tqdm\n",
    "\n",
    "# Enhanced Configuration with EfficientNet settings\n",
    "class Config:\n",
    "    data_dir = \"/data1/home/prakrutp/medical_imaging/dataset\"\n",
    "    csv_path = \"/data1/home/prakrutp/medical_imaging/dataset/Data_Entry_2017.csv\"\n",
    "    image_size = 512\n",
    "    batch_size = 16  # Start with smaller batch size\n",
    "    num_epochs = 100\n",
    "    learning_rate = 0.001\n",
    "    num_classes = 14\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # EfficientNet specific\n",
    "    model_name = \"tf_efficientnet_b3\"\n",
    "    use_pretrained = True\n",
    "    feature_dim = 1536\n",
    "    \n",
    "    # Advanced training\n",
    "    use_progressive_resizing = False  # Disable for now to debug\n",
    "    use_advanced_augmentation = True\n",
    "    use_class_weights = True\n",
    "    \n",
    "    # Split files\n",
    "    test_list_file = \"test_list.txt\"\n",
    "    train_val_list_file = \"train_val_list.txt\"\n",
    "    \n",
    "    # Checkpoint settings\n",
    "    checkpoint_dir = \"checkpoints_efficientnet\"\n",
    "    checkpoint_interval = 5\n",
    "    resume_training = True\n",
    "\n",
    "# Create checkpoint directory\n",
    "os.makedirs(Config.checkpoint_dir, exist_ok=True)\n",
    "\n",
    "# Optimized Class Weight Calculation\n",
    "def calculate_class_weights(dataset):\n",
    "    \"\"\"Calculate class weights for handling imbalance - OPTIMIZED VERSION\"\"\"\n",
    "    print(\"Calculating class weights...\")\n",
    "    \n",
    "    # Method 1: Use the dataframe directly (MUCH faster)\n",
    "    if hasattr(dataset, 'data_frame'):\n",
    "        print(\"Using dataframe for fast class weight calculation...\")\n",
    "        class_counts = np.zeros(Config.num_classes)\n",
    "        \n",
    "        for i, disease in enumerate(dataset.disease_classes):\n",
    "            class_counts[i] = dataset.data_frame[disease].sum()\n",
    "        \n",
    "        total_samples = len(dataset)\n",
    "        class_weights = total_samples / (Config.num_classes * np.maximum(class_counts, 1))\n",
    "        class_weights = class_weights / np.sum(class_weights) * Config.num_classes\n",
    "        \n",
    "    else:\n",
    "        # Method 2: Fallback to iterative (with progress bar)\n",
    "        print(\"Using iterative method with progress tracking...\")\n",
    "        class_counts = np.zeros(Config.num_classes)\n",
    "        \n",
    "        for idx in tqdm(range(len(dataset)), desc=\"Calculating class weights\"):\n",
    "            _, labels = dataset[idx]\n",
    "            class_counts += labels.numpy()\n",
    "    \n",
    "        # Avoid division by zero\n",
    "        class_counts = np.maximum(class_counts, 1)\n",
    "        \n",
    "        # Inverse frequency weighting\n",
    "        total_samples = len(dataset)\n",
    "        class_weights = total_samples / (Config.num_classes * class_counts)\n",
    "        \n",
    "        # Normalize weights\n",
    "        class_weights = class_weights / np.sum(class_weights) * Config.num_classes\n",
    "    \n",
    "    print(\"Class weights calculated:\")\n",
    "    for i, disease in enumerate(dataset.disease_classes):\n",
    "        print(f\"  {disease}: {class_weights[i]:.2f} (count: {class_counts[i]})\")\n",
    "    \n",
    "    return torch.FloatTensor(class_weights).to(Config.device)\n",
    "\n",
    "# Keep all your existing dataset and helper functions here (they're fine)\n",
    "class ChestXrayDataset(Dataset):\n",
    "    def __init__(self, csv_file, base_dir, image_list=None, transform=None):\n",
    "        self.df = pd.read_csv(csv_file)\n",
    "        self.base_dir = base_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "        self.disease_classes = [\n",
    "            'Atelectasis', 'Cardiomegaly', 'Effusion', 'Infiltration', \n",
    "            'Mass', 'Nodule', 'Pneumonia', 'Pneumothorax', \n",
    "            'Consolidation', 'Edema', 'Emphysema', 'Fibrosis', \n",
    "            'Pleural_Thickening', 'Hernia'\n",
    "        ]\n",
    "        \n",
    "        self._create_label_columns()\n",
    "        \n",
    "        if image_list is not None:\n",
    "            self.data_frame = self.df[self.df['Image Index'].isin(image_list)].reset_index(drop=True)\n",
    "        else:\n",
    "            self.data_frame = self.df\n",
    "        \n",
    "        print(f\"Dataset initialized with {len(self.data_frame)} images\")\n",
    "        \n",
    "    def _create_label_columns(self):\n",
    "        for disease in self.disease_classes:\n",
    "            self.df.loc[:, disease] = self.df['Finding Labels'].apply(\n",
    "                lambda x: 1 if disease in x else 0\n",
    "            )\n",
    "    \n",
    "    def _find_image_path(self, img_name):\n",
    "        for i in range(1, 13):\n",
    "            folder_name = f\"images_{i:03d}\"\n",
    "            possible_path = os.path.join(self.base_dir, folder_name, \"images\", img_name)\n",
    "            if os.path.exists(possible_path):\n",
    "                return possible_path\n",
    "        return os.path.join(self.base_dir, \"images_001\", \"images\", img_name)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.data_frame.iloc[idx]['Image Index']\n",
    "        img_path = self._find_image_path(img_name)\n",
    "        \n",
    "        try:\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not load image {img_path}: {e}\")\n",
    "            image = Image.new('RGB', (Config.image_size, Config.image_size), color='black')\n",
    "        \n",
    "        labels = []\n",
    "        for disease in self.disease_classes:\n",
    "            labels.append(self.data_frame.iloc[idx][disease])\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, torch.FloatTensor(labels)\n",
    "    \n",
    "    def get_class_distribution(self):\n",
    "        distribution = {}\n",
    "        for disease in self.disease_classes:\n",
    "            count = self.data_frame[disease].sum()\n",
    "            percentage = (count / len(self.data_frame)) * 100\n",
    "            distribution[disease] = {'count': count, 'percentage': percentage}\n",
    "        return distribution\n",
    "\n",
    "def load_split_file(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        image_names = [line.strip() for line in f.readlines()]\n",
    "    return image_names\n",
    "\n",
    "def create_datasets_from_splits(csv_file, base_dir, test_list_file, train_val_list_file, transform=None):\n",
    "    test_images = load_split_file(test_list_file)\n",
    "    train_val_images = load_split_file(train_val_list_file)\n",
    "    \n",
    "    print(f\"Test images: {len(test_images)}\")\n",
    "    print(f\"Train+Val images: {len(train_val_images)}\")\n",
    "    \n",
    "    train_images, val_images = train_test_split(\n",
    "        train_val_images, test_size=0.2, random_state=42\n",
    "    )\n",
    "    \n",
    "    print(f\"Train images: {len(train_images)}\")\n",
    "    print(f\"Validation images: {len(val_images)}\")\n",
    "    \n",
    "    train_dataset = ChestXrayDataset(\n",
    "        csv_file=csv_file,\n",
    "        base_dir=base_dir,\n",
    "        image_list=train_images,\n",
    "        transform=transform\n",
    "    )\n",
    "    \n",
    "    val_dataset = ChestXrayDataset(\n",
    "        csv_file=csv_file,\n",
    "        base_dir=base_dir,\n",
    "        image_list=val_images,\n",
    "        transform=transform\n",
    "    )\n",
    "    \n",
    "    test_dataset = ChestXrayDataset(\n",
    "        csv_file=csv_file,\n",
    "        base_dir=base_dir,\n",
    "        image_list=test_images,\n",
    "        transform=transform\n",
    "    )\n",
    "    \n",
    "    return train_dataset, val_dataset, test_dataset\n",
    "\n",
    "# Enhanced Data Augmentation for EfficientNet\n",
    "def get_advanced_transforms():\n",
    "    if Config.use_advanced_augmentation:\n",
    "        train_transform = transforms.Compose([\n",
    "            transforms.Resize((Config.image_size, Config.image_size)),\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.RandomRotation(degrees=15),\n",
    "            transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                               std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    else:\n",
    "        train_transform = transforms.Compose([\n",
    "            transforms.Resize((Config.image_size, Config.image_size)),\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                               std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "    \n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize((Config.image_size, Config.image_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                           std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    return train_transform, val_transform\n",
    "\n",
    "# Simplified EfficientNet Model (remove progressive training for now)\n",
    "class EfficientNetModel(nn.Module):\n",
    "    def __init__(self, num_classes=14, model_name=\"tf_efficientnet_b3\"):\n",
    "        super(EfficientNetModel, self).__init__()\n",
    "        \n",
    "        self.backbone = timm.create_model(\n",
    "            model_name, \n",
    "            pretrained=Config.use_pretrained,\n",
    "            num_classes=0\n",
    "        )\n",
    "        \n",
    "        if \"b3\" in model_name:\n",
    "            self.feature_dim = 1536\n",
    "        else:\n",
    "            self.feature_dim = self.backbone.num_features\n",
    "        \n",
    "        self.classifier = nn.Linear(self.feature_dim, num_classes)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        print(f\"Initialized {model_name} with {self.feature_dim} feature dimensions\")\n",
    "    \n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)\n",
    "        output = self.classifier(features)\n",
    "        output = self.sigmoid(output)\n",
    "        return output\n",
    "\n",
    "# Enhanced Loss Function\n",
    "class EnhancedWeightedLoss(nn.Module):\n",
    "    def __init__(self, class_weights=None):\n",
    "        super(EnhancedWeightedLoss, self).__init__()\n",
    "        self.class_weights = class_weights\n",
    "    \n",
    "    def forward(self, outputs, targets):\n",
    "        batch_size, num_classes = targets.shape\n",
    "        \n",
    "        # Simplified loss calculation\n",
    "        loss = torch.zeros(1, device=outputs.device)\n",
    "        \n",
    "        for i in range(num_classes):\n",
    "            class_output = outputs[:, i]\n",
    "            class_target = targets[:, i]\n",
    "            \n",
    "            # Binary cross entropy for each class\n",
    "            class_loss = - (class_target * torch.log(class_output + 1e-8) + \n",
    "                          (1 - class_target) * torch.log(1 - class_output + 1e-8))\n",
    "            \n",
    "            # Apply class weights if provided\n",
    "            if self.class_weights is not None:\n",
    "                class_loss = class_loss * self.class_weights[i]\n",
    "            \n",
    "            loss += class_loss.mean()\n",
    "        \n",
    "        return loss / num_classes\n",
    "\n",
    "# Checkpoint functions (simplified)\n",
    "def save_checkpoint(epoch, model, optimizer, train_losses, val_losses, val_auc_scores, best_auc, is_best=False):\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'train_losses': train_losses,\n",
    "        'val_losses': val_losses,\n",
    "        'val_auc_scores': val_auc_scores,\n",
    "        'best_auc': best_auc,\n",
    "    }\n",
    "    \n",
    "    filename = f\"checkpoint_epoch_{epoch:03d}.pth\"\n",
    "    checkpoint_path = os.path.join(Config.checkpoint_dir, filename)\n",
    "    torch.save(checkpoint, checkpoint_path)\n",
    "    \n",
    "    if is_best:\n",
    "        best_path = os.path.join(Config.checkpoint_dir, \"best_model.pth\")\n",
    "        torch.save(checkpoint, best_path)\n",
    "    \n",
    "    print(f\"Checkpoint saved: {checkpoint_path}\")\n",
    "\n",
    "def find_latest_checkpoint():\n",
    "    checkpoint_files = [f for f in os.listdir(Config.checkpoint_dir) if f.startswith('checkpoint_epoch_')]\n",
    "    if not checkpoint_files:\n",
    "        return None\n",
    "    epochs = [int(f.split('_')[2].split('.')[0]) for f in checkpoint_files]\n",
    "    latest_epoch = max(epochs)\n",
    "    return os.path.join(Config.checkpoint_dir, f\"checkpoint_epoch_{latest_epoch:03d}.pth\")\n",
    "\n",
    "# Training function with progress bars\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, start_epoch=0):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    val_auc_scores = []\n",
    "    best_auc = 0.0\n",
    "    \n",
    "    for epoch in range(start_epoch, num_epochs):\n",
    "        print(f'\\nEpoch {epoch+1}/{num_epochs}')\n",
    "        print('-' * 50)\n",
    "        \n",
    "        # Training phase\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        train_pbar = tqdm(train_loader, desc=f'Training Epoch {epoch+1}')\n",
    "        for batch_idx, (inputs, labels) in enumerate(train_pbar):\n",
    "            inputs = inputs.to(Config.device)\n",
    "            labels = labels.to(Config.device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            train_pbar.set_postfix({'Loss': f'{loss.item():.4f}'})\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_loader.dataset)\n",
    "        train_losses.append(epoch_loss)\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        all_labels = []\n",
    "        all_preds = []\n",
    "        \n",
    "        val_pbar = tqdm(val_loader, desc=f'Validation Epoch {epoch+1}')\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_pbar:\n",
    "                inputs = inputs.to(Config.device)\n",
    "                labels = labels.to(Config.device)\n",
    "                \n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item() * inputs.size(0)\n",
    "                \n",
    "                all_labels.append(labels.cpu().numpy())\n",
    "                all_preds.append(outputs.cpu().numpy())\n",
    "        \n",
    "        val_loss = val_loss / len(val_loader.dataset)\n",
    "        val_losses.append(val_loss)\n",
    "        \n",
    "        # Calculate AUC\n",
    "        all_labels = np.concatenate(all_labels)\n",
    "        all_preds = np.concatenate(all_preds)\n",
    "        \n",
    "        auc_scores = []\n",
    "        for i in range(Config.num_classes):\n",
    "            try:\n",
    "                if np.sum(all_labels[:, i]) > 0:\n",
    "                    auc = roc_auc_score(all_labels[:, i], all_preds[:, i])\n",
    "                    auc_scores.append(auc)\n",
    "                else:\n",
    "                    auc_scores.append(0.0)\n",
    "            except:\n",
    "                auc_scores.append(0.0)\n",
    "        \n",
    "        mean_auc = np.mean(auc_scores)\n",
    "        val_auc_scores.append(mean_auc)\n",
    "        \n",
    "        print(f'Training Loss: {epoch_loss:.4f}, Validation Loss: {val_loss:.4f}')\n",
    "        print(f'Validation AUC: {mean_auc:.4f}')\n",
    "        \n",
    "        # Save checkpoint\n",
    "        if mean_auc > best_auc:\n",
    "            best_auc = mean_auc\n",
    "            save_checkpoint(epoch+1, model, optimizer, train_losses, val_losses, val_auc_scores, best_auc, is_best=True)\n",
    "        elif (epoch + 1) % Config.checkpoint_interval == 0:\n",
    "            save_checkpoint(epoch+1, model, optimizer, train_losses, val_losses, val_auc_scores, best_auc)\n",
    "    \n",
    "    return model, train_losses, val_losses, val_auc_scores\n",
    "\n",
    "# Simplified Main Function\n",
    "def main_efficientnet():\n",
    "    print(\"ðŸš€ Setting up EFFICIENTNET model...\")\n",
    "    print(f\"Using device: {Config.device}\")\n",
    "    print(f\"Model: {Config.model_name}\")\n",
    "    \n",
    "    # Create transforms\n",
    "    train_transform, val_transform = get_advanced_transforms()\n",
    "    \n",
    "    # Create datasets\n",
    "    test_list_path = os.path.join(Config.data_dir, Config.test_list_file)\n",
    "    train_val_list_path = os.path.join(Config.data_dir, Config.train_val_list_file)\n",
    "    csv_path = os.path.join(Config.data_dir, Config.csv_path)\n",
    "    \n",
    "    print(\"Loading datasets...\")\n",
    "    train_dataset, val_dataset, test_dataset = create_datasets_from_splits(\n",
    "        csv_file=csv_path,\n",
    "        base_dir=Config.data_dir,\n",
    "        test_list_file=test_list_path,\n",
    "        train_val_list_file=train_val_list_path,\n",
    "        transform=train_transform\n",
    "    )\n",
    "    \n",
    "    val_dataset.transform = val_transform\n",
    "    test_dataset.transform = val_transform\n",
    "    \n",
    "    print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "    print(f\"Validation dataset size: {len(val_dataset)}\")\n",
    "    print(f\"Test dataset size: {len(test_dataset)}\")\n",
    "    \n",
    "    # Calculate class weights (optimized)\n",
    "    class_weights = None\n",
    "    if Config.use_class_weights:\n",
    "        class_weights = calculate_class_weights(train_dataset)\n",
    "    \n",
    "    # Create data loaders\n",
    "    print(\"Creating data loaders...\")\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=Config.batch_size, \n",
    "        shuffle=True, \n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, \n",
    "        batch_size=Config.batch_size, \n",
    "        shuffle=False, \n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    # Initialize model\n",
    "    print(f\"Initializing {Config.model_name}...\")\n",
    "    model = EfficientNetModel(\n",
    "        num_classes=Config.num_classes, \n",
    "        model_name=Config.model_name\n",
    "    )\n",
    "    model = model.to(Config.device)\n",
    "    \n",
    "    # Optimizer\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=Config.learning_rate, weight_decay=0.01)\n",
    "    criterion = EnhancedWeightedLoss(class_weights=class_weights)\n",
    "    \n",
    "    # Count parameters\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f\"Model initialized with {trainable_params:,} trainable parameters\")\n",
    "    \n",
    "    # Start training\n",
    "    print(\"\\nStarting training...\")\n",
    "    model, train_losses, val_losses, val_auc_scores = train_model(\n",
    "        model, train_loader, val_loader, criterion, optimizer, \n",
    "        Config.num_epochs\n",
    "    )\n",
    "    \n",
    "    print(\"\\nTraining completed!\")\n",
    "    print(f\"Best validation AUC: {max(val_auc_scores):.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main_efficientnet()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "med_env_fixed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
